{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AnZQpL_IZZZ"
   },
   "source": [
    "# LangChain multi-doc retriever with Quentin Tarantino scripts\n",
    "\n",
    "\n",
    "### Sources\n",
    "Video: https://www.youtube.com/watch?v=3yPBVii7Ct0\n",
    "Adapted from: https://colab.research.google.com/drive/1gyGZn_LZNrYXYXa-pltFExbptIe7DAPe?usp=sharing#scrollTo=XHVE9uFb3Ajj\n",
    "\n",
    "### Contents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqwsGJDhvAQ5"
   },
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J-KFB7J_u_3L",
    "outputId": "a29ed872-d0bc-41ef-bb72-b6a0fe426a08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.0.136\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://www.github.com/hwchase17/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages\n",
      "Requires: aiohttp, async-timeout, dataclasses-json, numpy, openapi-schema-pydantic, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dNA4TsHpu6OM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import config\n",
    "os.environ[\"OPENAI_API_KEY\"] = config.openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XHVE9uFb3Ajj"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UcQKUId3X2M"
   },
   "source": [
    "## 2. Load multiple text documents and split into chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./My Clippings.txt\r\n",
      "./pulp-fiction-1994.txt\r\n",
      "./hnswlib/CMakeLists.txt\r\n",
      "./reservoir-dogs-1992.txt\r\n",
      "./state_of_the_union.txt\r\n",
      "./jackie-brown-1997.txt\r\n"
     ]
    }
   ],
   "source": [
    "!find . -type f -name \"*.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PRSeXXc_3Ypj"
   },
   "outputs": [],
   "source": [
    "# Load and process the text files\n",
    "# loader = TextLoader('single_text_file.txt')\n",
    "loader = DirectoryLoader('', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3__nT0D4Fkmg"
   },
   "outputs": [],
   "source": [
    "#splitting the text into\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TlU5AlqY4gwj",
    "outputId": "d78fb098-3161-42cd-8ce9-5f98f4ef91d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "591"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bg6-9jwU4ja_",
    "outputId": "02f45055-0e09-42ba-9ff3-0e7850f06cae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='bank. You take more of a risk. Banks are\\neasier! Federal banks aren\\'t supposed to\\nstop you anyway, during a robbery. They\\'re\\ninsured, why should they care? You don\\'t\\neven need a gun in a federal bank. I heard\\nabout this guy, walked into a federal bank\\nwith a portable phone, handed the phone to\\nthe teller, the guy on the other end of\\nthe phone said: \"We got this guy\\'s little\\ngirl, and if you don\\'t give him all your\\nmoney, we\\'re gonna kill \\'er.\"\\nYOUNG WOMAN\\nDid it work?}\\nYOUNG MAN\\nFuckin\\' A it worked, that\\'s what I\\'m\\ntalkin\\' about! Knucklehead walks in a bank\\nwith a telephone, not a pistol, not a\\nshotgun, but a fuckin\\' phone, cleans the\\nplace out, and they don\\'t lift a fuckin\\'\\nfinger.\\nYOUNG WOMAN\\nDid they hurt the little girl?\\nYOUNG MAN\\nI don\\'t know. There probably never was a\\nlittle girl – the point of the story isn\\'t\\nthe little girl. The point of the story is\\nthey robbed the bank with a telephone.\\nYOUNG WOMAN\\nYou wanna rob banks?\\nYOUNG MAN\\nI\\'m not sayin\\' I wanna rob banks, I\\'m just', metadata={'source': 'pulp-fiction-1994.txt'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsYsIy8F4cdm"
   },
   "source": [
    "## 3. Create the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q_eTIZwf4Dk2",
    "outputId": "1cd293c4-716c-402d-d41b-045b6a264041"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: db\n"
     ]
    }
   ],
   "source": [
    "# Embed and store the texts\n",
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "persist_directory = 'db'\n",
    "\n",
    "## here we are using OpenAI embeddings but in future we will swap out to local embeddings\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=texts, \n",
    "                                 embedding=embedding,\n",
    "                                 persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uRfD_Te-47lb"
   },
   "outputs": [],
   "source": [
    "# persiste the db to disk\n",
    "vectordb.persist()\n",
    "vectordb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-h1y_eAHmD-",
    "outputId": "4a6097fb-e30e-4fa2-ff4d-b972ce7f6154"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: db\n"
     ]
    }
   ],
   "source": [
    "# Now we can load the persisted database from disk, and use it as normal. \n",
    "vectordb = Chroma(persist_directory=persist_directory, \n",
    "                  embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siLXR-XT0JoI"
   },
   "source": [
    "## 4. Make a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6ObunFU30Lxh"
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "cYA-H59u0Skn"
   },
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"Who is vincent vega?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h0iAuh_B0ZjE",
    "outputId": "2ffd1da1-ff6c-4ea9-c361-7230dbd5bdc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "jVWgPJXs1yRq"
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "H4N0IhRM0hHL",
    "outputId": "f8058122-1c8a-4c5b-f046-14a90eed5a3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'similarity'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.search_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4jXL9u-u0prF",
    "outputId": "2e6dd94e-bede-4e05-c841-9c755ecfef2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k': 2}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.search_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ia-4OXa5IeP"
   },
   "source": [
    "## 5. Make a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "MGx8XblM4shW"
   },
   "outputs": [],
   "source": [
    "# create the chain to answer questions \n",
    "qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(), \n",
    "                                  chain_type=\"stuff\", \n",
    "                                  retriever=retriever, \n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "LZEo26mw8e5k"
   },
   "outputs": [],
   "source": [
    "## Cite sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wKfX4vX-5RFT",
    "outputId": "b3902fd2-86cc-4020-86a9-99883a996d20"
   },
   "outputs": [],
   "source": [
    "# full example\n",
    "query = \"Who is Vincent Vega?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "olRm73t3rNt2",
    "outputId": "20fb1b17-6562-421d-a60e-c67b97ca67d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Who is Jackie Brown?',\n",
       " 'result': \" Jackie Brown is a very attractive black woman in her mid forties, though she looks like she's in her mid-thirties. She is a stewardess for the Cabo Air shuttle airline, flying from Los Angeles to Cabo San Lucas.\",\n",
       " 'source_documents': [Document(page_content=\"Jackie being led into the Admitting Area by TWO SHERIFFS . She's wearing her stewardess\\nuniform and carrying a small envelope with her belongings in it and her shoes. When Max was\\nimagining a woman in her forties, he had someone with a bit of wear and tear on them in mind.\\nBut this Jackie Brown's a knockout.\\nAs he watches her, she steps out of the County Jail slippers she was wearing and slips into her\\nshoes.\\nHe approaches, handing her his card.\\nMAX\\nMiss Brown... I'm Max Cherry. I'm your bail bondsman.\\nShe takes the card and shakes his hand saying nothing.\\nMAX (CONT'D)\\nI can give you a lift home if you'd like?\\nJACKIE\\nOkay.\\nINT. MAX'S CADILLAC – NIGHT\\nMax puts his key in the ignition, when Jackie asks;\\nJACKIE\\nAre you really a bail bondsman?\\nMAX\\nWho do you think I am?\\nShe doesn't answer.\\nMAX (CONT'D)\\nI gave you my card there.\\nJACKIE\\nCan I see your I.D.?\\nMAX\\nYou're serious?\\nShe waits.\\nMax digs the case out of his pocket, hands it to her, then reaches up and turns on the light\", metadata={'source': 'jackie-brown-1997.txt'}),\n",
       "  Document(page_content=\"JACKIE BROWN\\nScreenplay by\\nQuentin Tarantino\\nBased on the Novel by Elmore Leonard}\\nOPENING CREDITS\\nINT. LOS ANGELES INTERNATIONAL AIRPORT – DAY\\nWe hear the rhythm of funky seventies SOUL MUSIC .\\nThen SHE steps into FRAME .\\nShe is JACKIE BROWN , a stewardess dressed in her CABO AIR  uniform. (A little shuttle\\nairline that flies from Los Angeles to Cabo San Lucas. Approximate flight time: forty five\\nminutes)\\nJackie stands still as a people-mover slowly inches her through the airport. The CREDITS\\nAPEAR  and DISAPPEAR  in front of her.\\nJackie Brown is a very attractive black woman in her mid forties, though she looks like she's in\\nher mid-thirties.\\nThe people-mover reaches the end of the line, she steps off.\\nShe breezes through Customs and we follow her with a STEDICAM  as she strides through the\\nairport... She gets to her gate disappears inside the plane for a moment comes back out sans\\nflight bag picks up the microphone.\\nJACKIE\\n(into mike)\", metadata={'source': 'jackie-brown-1997.txt'})]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# break it down\n",
    "query = \"Who is Jackie Brown?\"\n",
    "llm_response = qa_chain(query)\n",
    "# process_llm_response(llm_response)\n",
    "llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IPIhZWAR5n3X",
    "outputId": "68914c62-f8ed-4e22-d889-7991df441d53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('similarity', <langchain.vectorstores.chroma.Chroma at 0x7f9f7dc82aa0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.retriever.search_type , qa_chain.retriever.vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_lp0_796P_-",
    "outputId": "64c01726-6e78-4c12-e409-2fdc839f6611"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "{context}\n",
      "\n",
      "Question: {question}\n",
      "Helpful Answer:\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSxVCnNi5h1-"
   },
   "source": [
    "## Deleteing the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H7xmepGJ2GAE",
    "outputId": "92b53c84-ef81-4000-db5a-2c2ec09db311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: db/ (stored 0%)\n",
      "  adding: db/chroma-collections.parquet (deflated 50%)\n",
      "  adding: db/index/ (stored 0%)\n",
      "  adding: db/index/index_metadata_59c51927-205d-4fd7-88d8-c7ba851bd2a5.pkl (deflated 5%)\n",
      "  adding: db/index/uuid_to_id_59c51927-205d-4fd7-88d8-c7ba851bd2a5.pkl (deflated 39%)\n",
      "  adding: db/index/index_59c51927-205d-4fd7-88d8-c7ba851bd2a5.bin (deflated 17%)\n",
      "  adding: db/index/id_to_uuid_59c51927-205d-4fd7-88d8-c7ba851bd2a5.pkl (deflated 35%)\n",
      "  adding: db/chroma-embeddings.parquet (deflated 29%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r db.zip ./db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jl84qGQt5Wu5"
   },
   "outputs": [],
   "source": [
    "# To cleanup, you can delete the collection\n",
    "vectordb.delete_collection()\n",
    "vectordb.persist()\n",
    "\n",
    "# delete the directory\n",
    "!rm -rf db/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2r0ZIBPJp-K"
   },
   "source": [
    "## Starting again loading the db\n",
    "\n",
    "restart the runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8pc7CM_mTQAt",
    "outputId": "f8e311fb-7d68-43af-ffd6-f66a9259766a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  db.zip\n",
      "   creating: db/\n",
      "  inflating: db/chroma-collections.parquet  \n",
      "   creating: db/index/\n",
      "  inflating: db/index/index_metadata_59c51927-205d-4fd7-88d8-c7ba851bd2a5.pkl  \n",
      "  inflating: db/index/uuid_to_id_59c51927-205d-4fd7-88d8-c7ba851bd2a5.pkl  \n",
      "  inflating: db/index/index_59c51927-205d-4fd7-88d8-c7ba851bd2a5.bin  \n",
      "  inflating: db/index/id_to_uuid_59c51927-205d-4fd7-88d8-c7ba851bd2a5.pkl  \n",
      "  inflating: db/chroma-embeddings.parquet  \n"
     ]
    }
   ],
   "source": [
    "!unzip db.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "us3F8ZKeRiz2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qK1nY4PkKYGo"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "396RyNbS4EXx",
    "outputId": "502d5c81-0823-4c00-89ca-7b4dd08bee26"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:chromadb:Using embedded DuckDB with persistence: data will be stored in: db\n"
     ]
    }
   ],
   "source": [
    "persist_directory = 'db'\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "vectordb2 = Chroma(persist_directory=persist_directory, \n",
    "                  embedding_function=embedding,\n",
    "                   )\n",
    "\n",
    "retriever = vectordb2.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F3vkSxxYKCZ9"
   },
   "outputs": [],
   "source": [
    "# Set up the turbo LLM\n",
    "turbo_llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name='gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PsR60NH5KCfj"
   },
   "outputs": [],
   "source": [
    "# create the chain to answer questions \n",
    "qa_chain = RetrievalQA.from_chain_type(llm=turbo_llm, \n",
    "                                  chain_type=\"stuff\", \n",
    "                                  retriever=retriever, \n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWulTG0eKCfk"
   },
   "outputs": [],
   "source": [
    "## Cite sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mDp-g2FtKCfk",
    "outputId": "766f131a-daaf-462f-842a-f7bd10a081fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pando raised $30 million in a Series B round, bringing its total raised to $45 million.\n",
      "\n",
      "\n",
      "Sources:\n",
      "new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
      "new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n"
     ]
    }
   ],
   "source": [
    "# full example\n",
    "query = \"How much money did Pando raise?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fPl26c-TbWw"
   },
   "source": [
    "### Chat prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwyuhrpu5XqM",
    "outputId": "0f2c8060-4002-49ba-8869-6a9990c2c6d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the users question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "{context}\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LcWXvSCHRvHO",
    "outputId": "d7a3acee-9ef1-4c08-b2a0-187f2cd90c8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{question}\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[1].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "978QWCeJSRdu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
