{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AnZQpL_IZZZ"
   },
   "source": [
    "# Question answering on multiple files using Quentin Tarantino scripts\n",
    "\n",
    "In this Notebook we will get multiple pdf's that we will use for question answering.\n",
    "\n",
    "\n",
    "### Contents\n",
    "0. Install packages\n",
    "1. Setting up\n",
    "2. Get the .pdf's and convert to txt\n",
    "3. Create the vector database and store the data in it\n",
    "4. Retrieve the data (search the source)\n",
    "5. Make a chain to ask the LLM the question\n",
    "6. Delete the database (option)\n",
    "\n",
    "### Sources\n",
    "- Video: https://www.youtube.com/watch?v=3yPBVii7Ct0\n",
    "- Adapted from: https://colab.research.google.com/drive/1gyGZn_LZNrYXYXa-pltFExbptIe7DAPe?usp=sharing#scrollTo=XHVE9uFb3Ajj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqwsGJDhvAQ5"
   },
   "source": [
    "## 1. Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J-KFB7J_u_3L",
    "outputId": "a29ed872-d0bc-41ef-bb72-b6a0fe426a08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\r\n",
      "Version: 0.0.136\r\n",
      "Summary: Building applications with LLMs through composability\r\n",
      "Home-page: https://www.github.com/hwchase17/langchain\r\n",
      "Author: \r\n",
      "Author-email: \r\n",
      "License: MIT\r\n",
      "Location: /Users/michielbontenbal/anaconda3/lib/python3.10/site-packages\r\n",
      "Requires: aiohttp, async-timeout, dataclasses-json, numpy, openapi-schema-pydantic, pydantic, PyYAML, requests, SQLAlchemy, tenacity\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "!pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dNA4TsHpu6OM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import config\n",
    "os.environ[\"OPENAI_API_KEY\"] = config.openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XHVE9uFb3Ajj"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UcQKUId3X2M"
   },
   "source": [
    "## 2. Get multiple pdf's and convert to txt documents and split into chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [........................................................] 198596 / 198596"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'jackie-brown-1997 (1).pdf'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wget\n",
    "wget.download('https://assets.scriptslug.com/live/pdf/scripts/pulp-fiction-1994.pdf')\n",
    "wget.download('https://assets.scriptslug.com/live/pdf/scripts/reservoir-dogs-1992.pdf')\n",
    "wget.download('https://assets.scriptslug.com/live/pdf/scripts/jackie-brown-1997.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pulp-fiction-1994.pdf', 'jackie-brown-1997.pdf', 'reservoir-dogs-1992.pdf']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "my_pdfs = glob.glob('*.pdf')\n",
    "my_pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a script to convert multiple pdf's to multiple txt's\n",
    "from PyPDF2 import PdfReader\n",
    "import os\n",
    "\n",
    "for i in range(len(my_pdfs)):\n",
    "    reader = PdfReader(my_pdfs[i])\n",
    "    number_of_pages = len(reader.pages)\n",
    "    file_name, ext = os.path.splitext(my_pdfs[i])\n",
    "    \n",
    "    textfile = open(file_name+\".txt\", \"w\")\n",
    "\n",
    "    for j in range (number_of_pages):\n",
    "        page = reader.pages[j]\n",
    "        textfile.write(page.extract_text())\n",
    "        textfile.write('}\\n')\n",
    "    textfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pulp-fiction-1994.txt',\n",
       " 'reservoir-dogs-1992.txt',\n",
       " 'state_of_the_union.txt',\n",
       " 'jackie-brown-1997.txt']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "my_txts = glob.glob('*.txt')\n",
    "my_txts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "PRSeXXc_3Ypj"
   },
   "outputs": [],
   "source": [
    "# Load and process the text files\n",
    "# loader = TextLoader('single_text_file.txt')\n",
    "loader = DirectoryLoader('', glob=\"*.txt\", loader_cls=TextLoader)\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "3__nT0D4Fkmg"
   },
   "outputs": [],
   "source": [
    "#splitting the .txt files into chunks of texts\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TlU5AlqY4gwj",
    "outputId": "d78fb098-3161-42cd-8ce9-5f98f4ef91d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "591"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bg6-9jwU4ja_",
    "outputId": "02f45055-0e09-42ba-9ff3-0e7850f06cae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='bank. You take more of a risk. Banks are\\neasier! Federal banks aren\\'t supposed to\\nstop you anyway, during a robbery. They\\'re\\ninsured, why should they care? You don\\'t\\neven need a gun in a federal bank. I heard\\nabout this guy, walked into a federal bank\\nwith a portable phone, handed the phone to\\nthe teller, the guy on the other end of\\nthe phone said: \"We got this guy\\'s little\\ngirl, and if you don\\'t give him all your\\nmoney, we\\'re gonna kill \\'er.\"\\nYOUNG WOMAN\\nDid it work?}\\nYOUNG MAN\\nFuckin\\' A it worked, that\\'s what I\\'m\\ntalkin\\' about! Knucklehead walks in a bank\\nwith a telephone, not a pistol, not a\\nshotgun, but a fuckin\\' phone, cleans the\\nplace out, and they don\\'t lift a fuckin\\'\\nfinger.\\nYOUNG WOMAN\\nDid they hurt the little girl?\\nYOUNG MAN\\nI don\\'t know. There probably never was a\\nlittle girl – the point of the story isn\\'t\\nthe little girl. The point of the story is\\nthey robbed the bank with a telephone.\\nYOUNG WOMAN\\nYou wanna rob banks?\\nYOUNG MAN\\nI\\'m not sayin\\' I wanna rob banks, I\\'m just', metadata={'source': 'pulp-fiction-1994.txt'})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the third text\n",
    "texts[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsYsIy8F4cdm"
   },
   "source": [
    "## 3. Create the vector database and store the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q_eTIZwf4Dk2",
    "outputId": "1cd293c4-716c-402d-d41b-045b6a264041"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: db\n"
     ]
    }
   ],
   "source": [
    "# Embed and store the texts\n",
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "persist_directory = 'db'\n",
    "\n",
    "## here we are using OpenAI embeddings but in future we will swap out to local embeddings\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=texts, \n",
    "                                 embedding=embedding,\n",
    "                                 persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "uRfD_Te-47lb"
   },
   "outputs": [],
   "source": [
    "# persiste the db to disk\n",
    "vectordb.persist()\n",
    "vectordb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-h1y_eAHmD-",
    "outputId": "4a6097fb-e30e-4fa2-ff4d-b972ce7f6154"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: db\n"
     ]
    }
   ],
   "source": [
    "# Now we can load the persisted database from disk, and use it as normal. \n",
    "vectordb = Chroma(persist_directory=persist_directory, \n",
    "                  embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siLXR-XT0JoI"
   },
   "source": [
    "## 4. Retrieve the data from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "6ObunFU30Lxh"
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "cYA-H59u0Skn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Blessed is he who, in the name of charity\\nand good will, shepherds the weak through\\nthe valley of darkness, for he is truly\\nhis brother\\'s keeper and the finder of\\nlost children. And I will strike down upon\\nthee with great vengeance and furious\\nanger those who attempt to poison and\\ndestroy my brothers. And you will know my\\nname is the Lord when I lay my vengeance\\nupon you.\"\\nThe two men EMPTY their guns at the same time on the sitting\\nBrett.\\nAGAINST BLACK, TITLE CARD:\\n \"VINCENT VEGA AND MARSELLUS WALLACE\\'S WIFE\"\\nFADE IN:\\nMEDIUM SHOT – BUTCH COOLIDGE\\nWe FADE UP on BUTCH COOLIDGE, a white, 26-year-old\\nprizefighter.Butch sits at a table wearing a red and blue high\\nschool athletic jacket. Talking to him OFF SCREEN is everybody\\'s\\nboss MARSELLUS WALLACE. The black man sounds like a cross between\\na gangster and a king.\\nMARSELLUS (O.S.)\\nI think you\\'re gonna find – when all this\\nshit is over and done – I think you\\'re\\ngonna find yourself one smilin\\'\\nmotherfucker. Thing is Butch, right now', metadata={'source': 'pulp-fiction-1994.txt'}),\n",
       " Document(page_content='Blessed is he who, in the name of charity\\nand good will, shepherds the weak through\\nthe valley of darkness, for he is truly\\nhis brother\\'s keeper and the finder of\\nlost children. And I will strike down upon\\nthee with great vengeance and furious\\nanger those who attempt to poison and\\ndestroy my brothers. And you will know my\\nname is the Lord when I lay my vengeance\\nupon you.\"\\nThe two men EMPTY their guns at the same time on the sitting\\nBrett.\\nAGAINST BLACK, TITLE CARD:\\n \"VINCENT VEGA AND MARSELLUS WALLACE\\'S WIFE\"\\nFADE IN:\\nMEDIUM SHOT – BUTCH COOLIDGE\\nWe FADE UP on BUTCH COOLIDGE, a white, 26-year-old\\nprizefighter.Butch sits at a table wearing a red and blue high\\nschool athletic jacket. Talking to him OFF SCREEN is everybody\\'s\\nboss MARSELLUS WALLACE. The black man sounds like a cross between\\na gangster and a king.\\nMARSELLUS (O.S.)\\nI think you\\'re gonna find – when all this\\nshit is over and done – I think you\\'re\\ngonna find yourself one smilin\\'\\nmotherfucker. Thing is Butch, right now', metadata={'source': 'pulp-fiction-1994.txt'}),\n",
       " Document(page_content='Blessed is he who, in the name of charity\\nand good will, shepherds the weak through\\nthe valley of darkness, for he is truly\\nhis brother\\'s keeper and the finder of\\nlost children. And I will strike down upon\\nthee with great vengeance and furious\\nanger those who attempt to poison and\\ndestroy my brothers. And you will know my\\nname is the Lord when I lay my vengeance\\nupon you.\"\\nThe two men EMPTY their guns at the same time on the sitting\\nBrett.\\nAGAINST BLACK, TITLE CARD:\\n \"VINCENT VEGA AND MARSELLUS WALLACE\\'S WIFE\"\\nFADE IN:\\nMEDIUM SHOT – BUTCH COOLIDGE\\nWe FADE UP on BUTCH COOLIDGE, a white, 26-year-old\\nprizefighter.Butch sits at a table wearing a red and blue high\\nschool athletic jacket. Talking to him OFF SCREEN is everybody\\'s\\nboss MARSELLUS WALLACE. The black man sounds like a cross between\\na gangster and a king.\\nMARSELLUS (O.S.)\\nI think you\\'re gonna find – when all this\\nshit is over and done – I think you\\'re\\ngonna find yourself one smilin\\'\\nmotherfucker. Thing is Butch, right now', metadata={'source': 'pulp-fiction-1994.txt'}),\n",
       " Document(page_content='Missus Mia Wallace.\\nED SULLIVAN\\n(into microphone)\\nAnd, uh, how \\'bout your fella here?\\nMIA\\n(into microphone)\\nVincent Vega.\\nED SULLIVAN\\n(into microphone)\\nAll right, let\\'s see what you can do. Take\\nit away!\\nMia and Vincent dance to Chuck Berry\\'s \"YOU NEVER CAN TELL\". They\\nmake hand movements as they dance.\\nINT. MARSELLUS WALLACE\\'S HOME – NIGHT\\nThe front door FLINGS open, and Mia and Vincent dance tango-style\\ninto the house, singing a cappella the song from the previous\\nscene. They finish their little dance, laughing.\\nThen...\\nThe two just stand face to face looking at each other.\\nVINCENT\\nWas than an uncomfortable silence?}\\nMIA\\nI don\\'t know what that was.\\n(pause)\\nMusic and drinks!\\nMia moves away to attend to both. Vincent hangs up his overcoat on\\na big bronze coat rack in the alcove.\\nVINCENT\\nI\\'m gonna take a piss.\\nMIA\\nThat was a little bit more information\\nthan I needed to know, but for right\\nahead.\\nVincent shuffles off to the john.', metadata={'source': 'pulp-fiction-1994.txt'})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(\"Who is vincent vega?\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h0iAuh_B0ZjE",
    "outputId": "2ffd1da1-ff6c-4ea9-c361-7230dbd5bdc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "jVWgPJXs1yRq"
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "H4N0IhRM0hHL",
    "outputId": "f8058122-1c8a-4c5b-f046-14a90eed5a3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'similarity'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.search_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4jXL9u-u0prF",
    "outputId": "2e6dd94e-bede-4e05-c841-9c755ecfef2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k': 2}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.search_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ia-4OXa5IeP"
   },
   "source": [
    "## 5. Make a chain to ask the LLM the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "MGx8XblM4shW"
   },
   "outputs": [],
   "source": [
    "# create the chain to answer questions \n",
    "qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(), \n",
    "                                  chain_type=\"stuff\", \n",
    "                                  retriever=retriever, \n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "LZEo26mw8e5k"
   },
   "outputs": [],
   "source": [
    "## Cite sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wKfX4vX-5RFT",
    "outputId": "b3902fd2-86cc-4020-86a9-99883a996d20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Vincent Vega is the person that Missus Mia Wallace introduces to Ed Sullivan and dances with to Chuck Berry's \"YOU NEVER CAN TELL\".\n",
      "\n",
      "\n",
      "Sources:\n",
      "pulp-fiction-1994.txt\n",
      "pulp-fiction-1994.txt\n"
     ]
    }
   ],
   "source": [
    "# first question\n",
    "query = \"Who is Vincent Vega?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "olRm73t3rNt2",
    "outputId": "20fb1b17-6562-421d-a60e-c67b97ca67d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Jackie Brown is a woman who was arrested and is being bailed out by Max Cherry.\n",
      "\n",
      "\n",
      "Sources:\n",
      "jackie-brown-1997.txt\n",
      "jackie-brown-1997.txt\n"
     ]
    }
   ],
   "source": [
    "# Second question\n",
    "query = \"Who is Jackie Brown?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mr. Orange is a cop.\n",
      "\n",
      "\n",
      "Sources:\n",
      "reservoir-dogs-1992.txt\n",
      "reservoir-dogs-1992.txt\n"
     ]
    }
   ],
   "source": [
    "# Third question\n",
    "query = \"Who is Mr. Orange?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IPIhZWAR5n3X",
    "outputId": "68914c62-f8ed-4e22-d889-7991df441d53"
   },
   "outputs": [],
   "source": [
    "qa_chain.retriever.search_type , qa_chain.retriever.vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_lp0_796P_-",
    "outputId": "64c01726-6e78-4c12-e409-2fdc839f6611"
   },
   "outputs": [],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSxVCnNi5h1-"
   },
   "source": [
    "## 6. Deleteing the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H7xmepGJ2GAE",
    "outputId": "92b53c84-ef81-4000-db5a-2c2ec09db311"
   },
   "outputs": [],
   "source": [
    "!zip -r db.zip ./db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jl84qGQt5Wu5"
   },
   "outputs": [],
   "source": [
    "# To cleanup, you can delete the collection\n",
    "vectordb.delete_collection()\n",
    "vectordb.persist()\n",
    "\n",
    "# delete the directory\n",
    "!rm -rf db/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2r0ZIBPJp-K"
   },
   "source": [
    "## Starting again loading the db\n",
    "\n",
    "restart the runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8pc7CM_mTQAt",
    "outputId": "f8e311fb-7d68-43af-ffd6-f66a9259766a"
   },
   "outputs": [],
   "source": [
    "!unzip db.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "us3F8ZKeRiz2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qK1nY4PkKYGo"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "396RyNbS4EXx",
    "outputId": "502d5c81-0823-4c00-89ca-7b4dd08bee26"
   },
   "outputs": [],
   "source": [
    "persist_directory = 'db'\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "vectordb2 = Chroma(persist_directory=persist_directory, \n",
    "                  embedding_function=embedding,\n",
    "                   )\n",
    "\n",
    "retriever = vectordb2.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F3vkSxxYKCZ9"
   },
   "outputs": [],
   "source": [
    "# Set up the turbo LLM\n",
    "turbo_llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name='gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PsR60NH5KCfj"
   },
   "outputs": [],
   "source": [
    "# create the chain to answer questions \n",
    "qa_chain = RetrievalQA.from_chain_type(llm=turbo_llm, \n",
    "                                  chain_type=\"stuff\", \n",
    "                                  retriever=retriever, \n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWulTG0eKCfk"
   },
   "outputs": [],
   "source": [
    "## Cite sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mDp-g2FtKCfk",
    "outputId": "766f131a-daaf-462f-842a-f7bd10a081fd"
   },
   "outputs": [],
   "source": [
    "# full example\n",
    "query = \"How much money did Pando raise?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fPl26c-TbWw"
   },
   "source": [
    "### Chat prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwyuhrpu5XqM",
    "outputId": "0f2c8060-4002-49ba-8869-6a9990c2c6d6"
   },
   "outputs": [],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LcWXvSCHRvHO",
    "outputId": "d7a3acee-9ef1-4c08-b2a0-187f2cd90c8f"
   },
   "outputs": [],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.messages[1].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "978QWCeJSRdu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
